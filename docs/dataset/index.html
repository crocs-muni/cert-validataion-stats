<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>cevast.dataset API documentation</title>
<meta name="description" content="This package is a collection of tools for working with certificate datasets." />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>cevast.dataset</code></h1>
</header>
<section id="section-intro">
<p>This package is a collection of tools for working with certificate datasets.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;This package is a collection of tools for working with certificate datasets.&#34;&#34;&#34;

__all__ = [
    &#39;DatasetType&#39;,
    &#39;DatasetState&#39;,
    &#39;Dataset&#39;,
    &#39;DatasetRepository&#39;,
    &#39;DatasetCollectionError&#39;,
    &#39;DatasetInvalidError&#39;,
    &#39;DatasetParsingError&#39;,
    &#39;DatasetManagerFactory&#39;,
    &#39;DatasetManager&#39;,
    &#39;DatasetManagerTask&#39;,
]
__version__ = &#39;0.1&#39;
__author__ = &#39;Radim Podola&#39;

from .dataset import (
    DatasetType,
    DatasetState,
    Dataset,
    DatasetRepository,
    DatasetCollectionError,
    DatasetInvalidError,
    DatasetParsingError,
)
from .manager_factory import DatasetManagerFactory
from .managers import DatasetManagerTask, DatasetManager</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="cevast.dataset.analyses" href="analyses/index.html">cevast.dataset.analyses</a></code></dt>
<dd>
<div class="desc"><p>This package provides tools for certificate datasets analysis.</p></div>
</dd>
<dt><code class="name"><a title="cevast.dataset.collectors" href="collectors/index.html">cevast.dataset.collectors</a></code></dt>
<dd>
<div class="desc"><p>This package provides tools for collecting certificate datasets.</p></div>
</dd>
<dt><code class="name"><a title="cevast.dataset.dataset" href="dataset.html">cevast.dataset.dataset</a></code></dt>
<dd>
<div class="desc"><p>This module contains structures and classes logically related to a certificate datasets.</p></div>
</dd>
<dt><code class="name"><a title="cevast.dataset.manager_factory" href="manager_factory.html">cevast.dataset.manager_factory</a></code></dt>
<dd>
<div class="desc"><p>This module contains DatasetManager factory implementation.</p></div>
</dd>
<dt><code class="name"><a title="cevast.dataset.managers" href="managers/index.html">cevast.dataset.managers</a></code></dt>
<dd>
<div class="desc"><p>This package provides certificate dataset managers …</p></div>
</dd>
<dt><code class="name"><a title="cevast.dataset.parsers" href="parsers/index.html">cevast.dataset.parsers</a></code></dt>
<dd>
<div class="desc"><p>This package provides tools for parsing certificate datasets.</p></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="cevast.dataset.Dataset"><code class="flex name class">
<span>class <span class="ident">Dataset</span></span>
<span>(</span><span>repository: str, dataset_type: Union[cevast.dataset.dataset.DatasetType, str], date_id: str, port: Union[str, int], extension: str = 'gz')</span>
</code></dt>
<dd>
<div class="desc"><p>Class representing a single dataset and providing an interface to the dataset on the filesystem.</p>
<p>Dataset is identified by <code>dataset_type</code>, <code>state</code> and filename where filename consists of mandatory
<code>date_id</code>, <code>port</code> number and optional suffix. date_id represents the date (or date range) when
the dataset was created (certificates were collected and added to the dataset), port is application
port on which was the data collceted, suffix can specify the dataset in various ways and is used
to distinguish the files internally. <code>dataset_type</code>, <code>date_id</code> and <code>port</code> are static identifiers provided
upon object initialization.</p>
<p>The dataset state is dynamic identifier that is the last part of its complete identification at the time.
Each dataset can be found at 1-N of the following generalized states:
- COLLECTED
- ANALYZED
- PARSED
- VALIDATED</p>
<p>Full Dataset path template: {repository}/{type}/{state}/{date_id}[_{port}][_suffix].{extension}</p>
<p>Initialize the static identifiers</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Dataset:
    &#34;&#34;&#34;
    Class representing a single dataset and providing an interface to the dataset on the filesystem.

    Dataset is identified by `dataset_type`, `state` and filename where filename consists of mandatory
    `date_id`, `port` number and optional suffix. date_id represents the date (or date range) when
    the dataset was created (certificates were collected and added to the dataset), port is application
    port on which was the data collceted, suffix can specify the dataset in various ways and is used
    to distinguish the files internally. `dataset_type`, `date_id` and `port` are static identifiers provided
    upon object initialization.

    The dataset state is dynamic identifier that is the last part of its complete identification at the time.
    Each dataset can be found at 1-N of the following generalized states:
        - COLLECTED
        - ANALYZED
        - PARSED
        - VALIDATED

    Full Dataset path template: {repository}/{type}/{state}/{date_id}[_{port}][_suffix].{extension}
    &#34;&#34;&#34;

    def __init__(self, repository: str, dataset_type: Union[DatasetType, str],
                 date_id: str, port: Union[str, int], extension: str = &#39;gz&#39;):
        &#34;&#34;&#34;Initialize the static identifiers&#34;&#34;&#34;
        # Validate and init dataset repository
        if not os.path.exists(repository):
            raise DatasetInvalidError(&#34;Repository %s not found&#34; % repository)
        self._repository = os.path.abspath(repository)
        # Validate and init dataset type
        if not DatasetType.validate(dataset_type):
            raise DatasetInvalidError(&#34;Dataset type %s is not valid.&#34; % dataset_type)
        self._dataset_type = str(dataset_type)
        self._date_id = date_id
        self._port = str(port) if port is not None else &#39;&#39;
        self._extension = extension

    @property
    def dataset_type(self) -&gt; str:
        &#34;&#34;&#34;Get the Dataset Type.&#34;&#34;&#34;
        return self._dataset_type

    @property
    def date(self) -&gt; str:
        &#34;&#34;&#34;Get the DATE ID.&#34;&#34;&#34;
        return self._date_id

    @property
    def port(self) -&gt; str:
        &#34;&#34;&#34;Get the PORT.&#34;&#34;&#34;
        return self._port

    @property
    def extension(self) -&gt; str:
        &#34;&#34;&#34;Get the extension.&#34;&#34;&#34;
        return self._extension

    @property
    def static_filename(self) -&gt; str:
        &#34;&#34;&#34;Get the static part of dataset filename.&#34;&#34;&#34;
        return Dataset.format_filename(self._date_id, self._port)

    @classmethod
    def from_full_path(cls, path: str) -&gt; &#39;Dataset&#39;:
        &#34;&#34;&#34;
        Initialize Dataset object from the given path,
        or return None if object cannot be initialized.
        &#34;&#34;&#34;
        template = r&#34;^(?P&lt;repo&gt;\S+)[/\\](?P&lt;type&gt;\S+)[/\\](?P&lt;state&gt;\S+)[/\\](?P&lt;date&gt;\d{8})(_(?P&lt;port&gt;\d+))?(_\S+)?\.(?P&lt;ext&gt;\S+)$&#34;
        match = re.match(template, path)
        if not match:
            return None
        try:
            return cls(repository=match.group(&#39;repo&#39;),
                       dataset_type=match.group(&#39;type&#39;),
                       date_id=match.group(&#39;date&#39;),
                       port=match.group(&#39;port&#39;),
                       extension=match.group(&#39;ext&#39;),
                       )
        except DatasetInvalidError:
            log.exception(&#34;Cannot initialize Dataset class from the given path.&#34;)
            return None

    @staticmethod
    def format_filename(date: str, port: str = &#39;&#39;, suffix: str = &#39;&#39;) -&gt; str:
        &#34;&#34;&#34;Format dataset filename.&#34;&#34;&#34;
        if port and suffix:
            return &#34;{}_{}_{}&#34;.format(date, port, suffix)
        if port or suffix:
            return &#34;{}_{}&#34;.format(date, port or suffix)
        return date

    def path(self, state: Union[DatasetState, str], physically: bool = True) -&gt; str:
        &#34;&#34;&#34;
        Assemble and return path to the dataset in given state.
        If `physically` flag is set and and path does not exist, create it.
        &#34;&#34;&#34;
        # Validate dataset state
        if not DatasetState.validate(state):
            raise DatasetInvalidError(&#34;Dataset state %s is not valid.&#34; % state)

        path = os.path.join(self._repository, self._dataset_type, str(state))

        if physically and not os.path.exists(path):
            log.info(&#34;Path &lt;%s&gt; does not exist yet, will be created.&#34;, path)
            os.makedirs(path)
        return path

    def full_path(self, state: Union[DatasetState, str], suffix: str = &#39;&#39;,
                  check_if_exists: bool = False, physically: bool = False) -&gt; str:
        &#34;&#34;&#34;
        Assemble and return full path to the dataset file in given state including custome suffix.
        Return None if `check_if_exists` and file does not exist.
        &#34;&#34;&#34;
        filename = Dataset.format_filename(self._date_id, self._port, suffix)
        path = os.path.join(self.path(state, physically), filename + &#39;.&#39; + self._extension)
        if check_if_exists and not os.path.exists(path):
            return None
        return path

    def delete(self, state: Union[DatasetState, str]) -&gt; None:
        &#34;&#34;&#34;Delete the dataset of given state from the repository.&#34;&#34;&#34;
        path = self.path(state, False)
        if not os.path.exists(path):
            return
        for file in directory_with_prefix(path, Dataset.format_filename(self._date_id, self._port)):
            log.debug(&#34;Will delete dataset &lt;%s&gt;.&#34;, file)
            os.remove(file)
        if not os.listdir(path):
            log.info(&#34;No more datasets in state &lt;%s&gt;, directory will be deleted.&#34;, state)
            os.rmdir(path)

    def purge(self) -&gt; None:
        &#34;&#34;&#34;Delete all datasets of specified type from the repository.&#34;&#34;&#34;
        shutil.rmtree(os.path.join(self._repository, self._dataset_type), ignore_errors=True)

    def get(self, state: Union[DatasetState, str], suffix: str = &#39;&#39;, full_path: bool = False) -&gt; Tuple[str]:
        &#34;&#34;&#34;Return all datasets stored in the dataset repository matching the paramaters.&#34;&#34;&#34;
        filename = Dataset.format_filename(self._date_id, self._port, suffix)
        path = self.path(state, False)
        return tuple(directory_with_prefix(path, filename, not full_path))

    def exists(self, state: Union[DatasetState, str]) -&gt; bool:
        &#34;&#34;&#34;Test if the dataset exists in given state.&#34;&#34;&#34;
        path = self.path(state, False)
        for _ in directory_with_prefix(path, Dataset.format_filename(self._date_id, self._port)):
            return True
        return False

    def exists_any(self) -&gt; bool:
        &#34;&#34;&#34;Test if any dataset (of the specified type) exists.&#34;&#34;&#34;
        for state in DatasetState:
            if self.exists(state):
                return True
        return False

    def move(self, state: Union[DatasetState, str], source: str, format_name: bool = True) -&gt; None:
        &#34;&#34;&#34;
        Move the source file to the repository of the dataset of given state.
        If `format_name` is true, then name is formatted.
        &#34;&#34;&#34;
        if os.path.exists(source):
            path = self.path(state)
            filename = os.path.basename(source)
            if format_name:
                filename = Dataset.format_filename(self._date_id, self._port, filename)
            shutil.move(os.path.abspath(source), os.path.join(path, filename))

    def __str__(self):
        return os.path.join(self._repository, self._dataset_type, &#34;{}&#34;, Dataset.format_filename(self._date_id, self._port))

    def __repr__(self):
        return &#34;&lt;%s.%s dataset_type=%s, date_id=%s, port=%s&gt;&#34; % (
            self.__class__.__module__,
            self.__class__.__qualname__,
            self._dataset_type,
            self._date_id,
            self._port,
        )

    def __eq__(self, other):
        if not isinstance(other, Dataset):
            # don&#39;t attempt to compare against unrelated types
            return NotImplemented

        return self._port == other.port and self._date_id == other.date and self._dataset_type == other.dataset_type

    def __hash__(self):
        return hash((self._port, self._date_id, self._dataset_type))</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="cevast.dataset.Dataset.format_filename"><code class="name flex">
<span>def <span class="ident">format_filename</span></span>(<span>date: str, port: str = '', suffix: str = '') -> str</span>
</code></dt>
<dd>
<div class="desc"><p>Format dataset filename.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def format_filename(date: str, port: str = &#39;&#39;, suffix: str = &#39;&#39;) -&gt; str:
    &#34;&#34;&#34;Format dataset filename.&#34;&#34;&#34;
    if port and suffix:
        return &#34;{}_{}_{}&#34;.format(date, port, suffix)
    if port or suffix:
        return &#34;{}_{}&#34;.format(date, port or suffix)
    return date</code></pre>
</details>
</dd>
<dt id="cevast.dataset.Dataset.from_full_path"><code class="name flex">
<span>def <span class="ident">from_full_path</span></span>(<span>path: str) -> <a title="cevast.dataset.dataset.Dataset" href="dataset.html#cevast.dataset.dataset.Dataset">Dataset</a></span>
</code></dt>
<dd>
<div class="desc"><p>Initialize Dataset object from the given path,
or return None if object cannot be initialized.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def from_full_path(cls, path: str) -&gt; &#39;Dataset&#39;:
    &#34;&#34;&#34;
    Initialize Dataset object from the given path,
    or return None if object cannot be initialized.
    &#34;&#34;&#34;
    template = r&#34;^(?P&lt;repo&gt;\S+)[/\\](?P&lt;type&gt;\S+)[/\\](?P&lt;state&gt;\S+)[/\\](?P&lt;date&gt;\d{8})(_(?P&lt;port&gt;\d+))?(_\S+)?\.(?P&lt;ext&gt;\S+)$&#34;
    match = re.match(template, path)
    if not match:
        return None
    try:
        return cls(repository=match.group(&#39;repo&#39;),
                   dataset_type=match.group(&#39;type&#39;),
                   date_id=match.group(&#39;date&#39;),
                   port=match.group(&#39;port&#39;),
                   extension=match.group(&#39;ext&#39;),
                   )
    except DatasetInvalidError:
        log.exception(&#34;Cannot initialize Dataset class from the given path.&#34;)
        return None</code></pre>
</details>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="cevast.dataset.Dataset.dataset_type"><code class="name">var <span class="ident">dataset_type</span> : str</code></dt>
<dd>
<div class="desc"><p>Get the Dataset Type.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def dataset_type(self) -&gt; str:
    &#34;&#34;&#34;Get the Dataset Type.&#34;&#34;&#34;
    return self._dataset_type</code></pre>
</details>
</dd>
<dt id="cevast.dataset.Dataset.date"><code class="name">var <span class="ident">date</span> : str</code></dt>
<dd>
<div class="desc"><p>Get the DATE ID.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def date(self) -&gt; str:
    &#34;&#34;&#34;Get the DATE ID.&#34;&#34;&#34;
    return self._date_id</code></pre>
</details>
</dd>
<dt id="cevast.dataset.Dataset.extension"><code class="name">var <span class="ident">extension</span> : str</code></dt>
<dd>
<div class="desc"><p>Get the extension.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def extension(self) -&gt; str:
    &#34;&#34;&#34;Get the extension.&#34;&#34;&#34;
    return self._extension</code></pre>
</details>
</dd>
<dt id="cevast.dataset.Dataset.port"><code class="name">var <span class="ident">port</span> : str</code></dt>
<dd>
<div class="desc"><p>Get the PORT.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def port(self) -&gt; str:
    &#34;&#34;&#34;Get the PORT.&#34;&#34;&#34;
    return self._port</code></pre>
</details>
</dd>
<dt id="cevast.dataset.Dataset.static_filename"><code class="name">var <span class="ident">static_filename</span> : str</code></dt>
<dd>
<div class="desc"><p>Get the static part of dataset filename.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def static_filename(self) -&gt; str:
    &#34;&#34;&#34;Get the static part of dataset filename.&#34;&#34;&#34;
    return Dataset.format_filename(self._date_id, self._port)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="cevast.dataset.Dataset.delete"><code class="name flex">
<span>def <span class="ident">delete</span></span>(<span>self, state: Union[cevast.dataset.dataset.DatasetState, str]) -> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Delete the dataset of given state from the repository.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete(self, state: Union[DatasetState, str]) -&gt; None:
    &#34;&#34;&#34;Delete the dataset of given state from the repository.&#34;&#34;&#34;
    path = self.path(state, False)
    if not os.path.exists(path):
        return
    for file in directory_with_prefix(path, Dataset.format_filename(self._date_id, self._port)):
        log.debug(&#34;Will delete dataset &lt;%s&gt;.&#34;, file)
        os.remove(file)
    if not os.listdir(path):
        log.info(&#34;No more datasets in state &lt;%s&gt;, directory will be deleted.&#34;, state)
        os.rmdir(path)</code></pre>
</details>
</dd>
<dt id="cevast.dataset.Dataset.exists"><code class="name flex">
<span>def <span class="ident">exists</span></span>(<span>self, state: Union[cevast.dataset.dataset.DatasetState, str]) -> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Test if the dataset exists in given state.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def exists(self, state: Union[DatasetState, str]) -&gt; bool:
    &#34;&#34;&#34;Test if the dataset exists in given state.&#34;&#34;&#34;
    path = self.path(state, False)
    for _ in directory_with_prefix(path, Dataset.format_filename(self._date_id, self._port)):
        return True
    return False</code></pre>
</details>
</dd>
<dt id="cevast.dataset.Dataset.exists_any"><code class="name flex">
<span>def <span class="ident">exists_any</span></span>(<span>self) -> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Test if any dataset (of the specified type) exists.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def exists_any(self) -&gt; bool:
    &#34;&#34;&#34;Test if any dataset (of the specified type) exists.&#34;&#34;&#34;
    for state in DatasetState:
        if self.exists(state):
            return True
    return False</code></pre>
</details>
</dd>
<dt id="cevast.dataset.Dataset.full_path"><code class="name flex">
<span>def <span class="ident">full_path</span></span>(<span>self, state: Union[cevast.dataset.dataset.DatasetState, str], suffix: str = '', check_if_exists: bool = False, physically: bool = False) -> str</span>
</code></dt>
<dd>
<div class="desc"><p>Assemble and return full path to the dataset file in given state including custome suffix.
Return None if <code>check_if_exists</code> and file does not exist.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def full_path(self, state: Union[DatasetState, str], suffix: str = &#39;&#39;,
              check_if_exists: bool = False, physically: bool = False) -&gt; str:
    &#34;&#34;&#34;
    Assemble and return full path to the dataset file in given state including custome suffix.
    Return None if `check_if_exists` and file does not exist.
    &#34;&#34;&#34;
    filename = Dataset.format_filename(self._date_id, self._port, suffix)
    path = os.path.join(self.path(state, physically), filename + &#39;.&#39; + self._extension)
    if check_if_exists and not os.path.exists(path):
        return None
    return path</code></pre>
</details>
</dd>
<dt id="cevast.dataset.Dataset.get"><code class="name flex">
<span>def <span class="ident">get</span></span>(<span>self, state: Union[cevast.dataset.dataset.DatasetState, str], suffix: str = '', full_path: bool = False) -> Tuple[str]</span>
</code></dt>
<dd>
<div class="desc"><p>Return all datasets stored in the dataset repository matching the paramaters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get(self, state: Union[DatasetState, str], suffix: str = &#39;&#39;, full_path: bool = False) -&gt; Tuple[str]:
    &#34;&#34;&#34;Return all datasets stored in the dataset repository matching the paramaters.&#34;&#34;&#34;
    filename = Dataset.format_filename(self._date_id, self._port, suffix)
    path = self.path(state, False)
    return tuple(directory_with_prefix(path, filename, not full_path))</code></pre>
</details>
</dd>
<dt id="cevast.dataset.Dataset.move"><code class="name flex">
<span>def <span class="ident">move</span></span>(<span>self, state: Union[cevast.dataset.dataset.DatasetState, str], source: str, format_name: bool = True) -> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Move the source file to the repository of the dataset of given state.
If <code>format_name</code> is true, then name is formatted.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def move(self, state: Union[DatasetState, str], source: str, format_name: bool = True) -&gt; None:
    &#34;&#34;&#34;
    Move the source file to the repository of the dataset of given state.
    If `format_name` is true, then name is formatted.
    &#34;&#34;&#34;
    if os.path.exists(source):
        path = self.path(state)
        filename = os.path.basename(source)
        if format_name:
            filename = Dataset.format_filename(self._date_id, self._port, filename)
        shutil.move(os.path.abspath(source), os.path.join(path, filename))</code></pre>
</details>
</dd>
<dt id="cevast.dataset.Dataset.path"><code class="name flex">
<span>def <span class="ident">path</span></span>(<span>self, state: Union[cevast.dataset.dataset.DatasetState, str], physically: bool = True) -> str</span>
</code></dt>
<dd>
<div class="desc"><p>Assemble and return path to the dataset in given state.
If <code>physically</code> flag is set and and path does not exist, create it.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def path(self, state: Union[DatasetState, str], physically: bool = True) -&gt; str:
    &#34;&#34;&#34;
    Assemble and return path to the dataset in given state.
    If `physically` flag is set and and path does not exist, create it.
    &#34;&#34;&#34;
    # Validate dataset state
    if not DatasetState.validate(state):
        raise DatasetInvalidError(&#34;Dataset state %s is not valid.&#34; % state)

    path = os.path.join(self._repository, self._dataset_type, str(state))

    if physically and not os.path.exists(path):
        log.info(&#34;Path &lt;%s&gt; does not exist yet, will be created.&#34;, path)
        os.makedirs(path)
    return path</code></pre>
</details>
</dd>
<dt id="cevast.dataset.Dataset.purge"><code class="name flex">
<span>def <span class="ident">purge</span></span>(<span>self) -> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Delete all datasets of specified type from the repository.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def purge(self) -&gt; None:
    &#34;&#34;&#34;Delete all datasets of specified type from the repository.&#34;&#34;&#34;
    shutil.rmtree(os.path.join(self._repository, self._dataset_type), ignore_errors=True)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="cevast.dataset.DatasetCollectionError"><code class="flex name class">
<span>class <span class="ident">DatasetCollectionError</span></span>
<span>(</span><span>...)</span>
</code></dt>
<dd>
<div class="desc"><p>Raised when dataset collection fails.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DatasetCollectionError(ValueError):
    &#34;&#34;&#34;Raised when dataset collection fails.&#34;&#34;&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.ValueError</li>
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="cevast.dataset.DatasetInvalidError"><code class="flex name class">
<span>class <span class="ident">DatasetInvalidError</span></span>
<span>(</span><span>...)</span>
</code></dt>
<dd>
<div class="desc"><p>Raised when the dataset has an invalid identifier.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DatasetInvalidError(ValueError):
    &#34;&#34;&#34;Raised when the dataset has an invalid identifier.&#34;&#34;&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.ValueError</li>
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="cevast.dataset.DatasetManager"><code class="flex name class">
<span>class <span class="ident">DatasetManager</span></span>
<span>(</span><span>repository: str, date: <method 'date' of 'datetime.datetime' objects> = datetime.date(2020, 6, 28), ports: Tuple[str] = ('443',), cpu_cores: int = 1)</span>
</code></dt>
<dd>
<div class="desc"><p>An abstract DatasetManager class representing an interface that can be used to perform
various tasks with a certificate dataset.</p>
<p>For Manager to perform a task, a repository path and date must be provided. Date works
as an identifier of the dataset even though the date don't need to match exactly
- the newest dataset by that date is identified. Additionally a port number might be
used to more specify the dataset.</p>
<p>DatasetManager offers performing tasks independently or running a series of tasks at once
by <code>run</code> method (usefull for performing tasks that would be rather complex and/or long-lasting
running separatelly). Running a series might also be more optimized.</p>
<p>Initialize Manager.
<code>repository</code> is dataset repository,
'date' is date,
'ports' is list of ports more specifying datasets,
'cpu_cores' is maximum number of CPU cores that might be used.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DatasetManager(ABC):
    &#34;&#34;&#34;
    An abstract DatasetManager class representing an interface that can be used to perform
    various tasks with a certificate dataset.

    For Manager to perform a task, a repository path and date must be provided. Date works
    as an identifier of the dataset even though the date don&#39;t need to match exactly
     - the newest dataset by that date is identified. Additionally a port number might be
    used to more specify the dataset.

    DatasetManager offers performing tasks independently or running a series of tasks at once
    by `run` method (usefull for performing tasks that would be rather complex and/or long-lasting
    running separatelly). Running a series might also be more optimized.
    &#34;&#34;&#34;

    @property
    @abstractclassmethod
    def dataset_type(cls) -&gt; DatasetType:
        &#34;&#34;&#34;
        Dataset type property used to identify a manager specification.
        &#34;&#34;&#34;

    @abstractmethod
    def __init__(self, repository: str, date: datetime.date = datetime.today().date(),
                 ports: Tuple[str] = (&#39;443&#39;,), cpu_cores: int = 1):
        &#34;&#34;&#34;
        Initialize Manager.
        `repository` is dataset repository,
        &#39;date&#39; is date,
        &#39;ports&#39; is list of ports more specifying datasets,
        &#39;cpu_cores&#39; is maximum number of CPU cores that might be used.
        &#34;&#34;&#34;

    @abstractmethod
    def run(self, task_pipline: Tuple[Tuple[DatasetManagerTask, dict]]) -&gt; None:
        &#34;&#34;&#34;
        Run a series of tasks.
        `task_pipline` is tuple composed of the required tasks in form of pairs (&#39;task&#39;, &#39;cfg&#39;), where:
            - &#39;task&#39; is supported DatasetManagerTask,
            - &#39;cfg&#39; is dictionary filled of parameters that will be passed to individual task methods.
        Caller function must ensure that &#39;cfg&#39; parameters match task method&#39;s declaration.
        TODO make cfg dict optional
        &#34;&#34;&#34;

    @abstractmethod
    def collect(self, api_key: str = None) -&gt; Tuple[Dataset]:
        &#34;&#34;&#34;
        Collect a dataset.
        `api_key` is API access key that might be needed to retrieve datasets (depends on type implementation).
        Return tuple of collected Datasets.
        &#34;&#34;&#34;

    @abstractmethod
    def analyse(self, methods: list = None) -&gt; Tuple[Dataset]:
        &#34;&#34;&#34;
        Analyse a dataset with given methods.
        Return tuple of analysed Datasets.
        &#34;&#34;&#34;

    @abstractmethod
    def parse(self, certdb: CertDB) -&gt; Tuple[Dataset]:
        &#34;&#34;&#34;
        Parse a dataset.
        `certdb` is CertDB instance to work with (to insert parsed certificates to).
        Return tuple of parsed Datasets.
        &#34;&#34;&#34;

    @abstractmethod
    def validate(self, validator: Type[CertValidator], validator_cfg: dict) -&gt; Tuple[Dataset]:
        &#34;&#34;&#34;
        Validate a dataset with given validor.
        `validator` is a CertValidator class,
        `validator_cfg` is a dictionary with validator paramaters that will be passed to the initializer.

        Call to validator is performed like this: validator(cert_chain, **validator_cfg).

        Return tuple of validated Datasets.
        &#34;&#34;&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="cevast.dataset.managers.rapid.RapidDatasetManager" href="managers/rapid.html#cevast.dataset.managers.rapid.RapidDatasetManager">RapidDatasetManager</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="cevast.dataset.DatasetManager.dataset_type"><code class="name">var <span class="ident">dataset_type</span></code></dt>
<dd>
<div class="desc"><p>A decorator indicating abstract classmethods.</p>
<p>Similar to abstractmethod.</p>
<h2 id="usage">Usage</h2>
<p>class C(metaclass=ABCMeta):
@abstractclassmethod
def my_abstract_classmethod(cls, &hellip;):
&hellip;</p>
<p>'abstractclassmethod' is deprecated. Use 'classmethod' with
'abstractmethod' instead.</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="cevast.dataset.DatasetManager.analyse"><code class="name flex">
<span>def <span class="ident">analyse</span></span>(<span>self, methods: list = None) -> Tuple[<a title="cevast.dataset.dataset.Dataset" href="dataset.html#cevast.dataset.dataset.Dataset">Dataset</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Analyse a dataset with given methods.
Return tuple of analysed Datasets.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def analyse(self, methods: list = None) -&gt; Tuple[Dataset]:
    &#34;&#34;&#34;
    Analyse a dataset with given methods.
    Return tuple of analysed Datasets.
    &#34;&#34;&#34;</code></pre>
</details>
</dd>
<dt id="cevast.dataset.DatasetManager.collect"><code class="name flex">
<span>def <span class="ident">collect</span></span>(<span>self, api_key: str = None) -> Tuple[<a title="cevast.dataset.dataset.Dataset" href="dataset.html#cevast.dataset.dataset.Dataset">Dataset</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Collect a dataset.
<code>api_key</code> is API access key that might be needed to retrieve datasets (depends on type implementation).
Return tuple of collected Datasets.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def collect(self, api_key: str = None) -&gt; Tuple[Dataset]:
    &#34;&#34;&#34;
    Collect a dataset.
    `api_key` is API access key that might be needed to retrieve datasets (depends on type implementation).
    Return tuple of collected Datasets.
    &#34;&#34;&#34;</code></pre>
</details>
</dd>
<dt id="cevast.dataset.DatasetManager.parse"><code class="name flex">
<span>def <span class="ident">parse</span></span>(<span>self, certdb: <a title="cevast.certdb.cert_db.CertDB" href="../certdb/cert_db.html#cevast.certdb.cert_db.CertDB">CertDB</a>) -> Tuple[<a title="cevast.dataset.dataset.Dataset" href="dataset.html#cevast.dataset.dataset.Dataset">Dataset</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Parse a dataset.
<code>certdb</code> is CertDB instance to work with (to insert parsed certificates to).
Return tuple of parsed Datasets.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def parse(self, certdb: CertDB) -&gt; Tuple[Dataset]:
    &#34;&#34;&#34;
    Parse a dataset.
    `certdb` is CertDB instance to work with (to insert parsed certificates to).
    Return tuple of parsed Datasets.
    &#34;&#34;&#34;</code></pre>
</details>
</dd>
<dt id="cevast.dataset.DatasetManager.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self, task_pipline: Tuple[Tuple[cevast.dataset.managers.manager.DatasetManagerTask, dict]]) -> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Run a series of tasks.
<code>task_pipline</code> is tuple composed of the required tasks in form of pairs ('task', 'cfg'), where:
- 'task' is supported DatasetManagerTask,
- 'cfg' is dictionary filled of parameters that will be passed to individual task methods.
Caller function must ensure that 'cfg' parameters match task method's declaration.
TODO make cfg dict optional</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def run(self, task_pipline: Tuple[Tuple[DatasetManagerTask, dict]]) -&gt; None:
    &#34;&#34;&#34;
    Run a series of tasks.
    `task_pipline` is tuple composed of the required tasks in form of pairs (&#39;task&#39;, &#39;cfg&#39;), where:
        - &#39;task&#39; is supported DatasetManagerTask,
        - &#39;cfg&#39; is dictionary filled of parameters that will be passed to individual task methods.
    Caller function must ensure that &#39;cfg&#39; parameters match task method&#39;s declaration.
    TODO make cfg dict optional
    &#34;&#34;&#34;</code></pre>
</details>
</dd>
<dt id="cevast.dataset.DatasetManager.validate"><code class="name flex">
<span>def <span class="ident">validate</span></span>(<span>self, validator: Type[<a title="cevast.validation.validator.CertValidator" href="../validation/validator.html#cevast.validation.validator.CertValidator">CertValidator</a>], validator_cfg: dict) -> Tuple[<a title="cevast.dataset.dataset.Dataset" href="dataset.html#cevast.dataset.dataset.Dataset">Dataset</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Validate a dataset with given validor.
<code>validator</code> is a CertValidator class,
<code>validator_cfg</code> is a dictionary with validator paramaters that will be passed to the initializer.</p>
<p>Call to validator is performed like this: validator(cert_chain, **validator_cfg).</p>
<p>Return tuple of validated Datasets.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def validate(self, validator: Type[CertValidator], validator_cfg: dict) -&gt; Tuple[Dataset]:
    &#34;&#34;&#34;
    Validate a dataset with given validor.
    `validator` is a CertValidator class,
    `validator_cfg` is a dictionary with validator paramaters that will be passed to the initializer.

    Call to validator is performed like this: validator(cert_chain, **validator_cfg).

    Return tuple of validated Datasets.
    &#34;&#34;&#34;</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="cevast.dataset.DatasetManagerFactory"><code class="flex name class">
<span>class <span class="ident">DatasetManagerFactory</span></span>
</code></dt>
<dd>
<div class="desc"><p>Factory class providing the specific DatasetManager class based on DatasetType.</p>
<div class="admonition important">
<p class="admonition-title">Important:&ensp;DatasetManager classes are registered automatically. To add a new</p>
</div>
<p>specialized DatasetManager class, it must inherit DatasetManager and be placed
in "cevast.dataset.managers" package.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DatasetManagerFactory:
    &#34;&#34;&#34;
    Factory class providing the specific DatasetManager class based on DatasetType.

    .. IMPORTANT:: DatasetManager classes are registered automatically. To add a new
    specialized DatasetManager class, it must inherit DatasetManager and be placed
    in &#34;cevast.dataset.managers&#34; package.
    &#34;&#34;&#34;

    __classes = {}

    @classmethod
    def __load_classes(cls):
        &#34;&#34;&#34;
        Automatically initialize lookup dictionary with subclasses of DatasetManager class
        that are visible to the Python interpreter (obtained from `type.__subclasses__()`).
        &#34;&#34;&#34;
        for manager_class in managers.DatasetManager.__subclasses__():
            if hasattr(manager_class, &#39;dataset_type&#39;):
                cls.__classes[str(manager_class.dataset_type)] = manager_class

    @classmethod
    def get_manager(cls, dataset_type: Union[DatasetType, str]) -&gt; Type[managers.DatasetManager]:
        &#34;&#34;&#34;Return a corresponding DatasetManager class based on `dataset_type`.&#34;&#34;&#34;
        if not cls.__classes:
            cls.__load_classes()

        # Validate and init dataset manager
        if not DatasetType.validate(dataset_type):
            raise DatasetInvalidError(&#34;Dataset type %s is not valid.&#34; % dataset_type)
        if str(dataset_type) not in cls.__classes:
            raise DatasetInvalidError(&#34;Dataset type %s has no manager.&#34; % dataset_type)

        return cls.__classes[str(dataset_type)]</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="cevast.dataset.DatasetManagerFactory.get_manager"><code class="name flex">
<span>def <span class="ident">get_manager</span></span>(<span>dataset_type: Union[cevast.dataset.dataset.DatasetType, str]) -> Type[<a title="cevast.dataset.managers.manager.DatasetManager" href="managers/manager.html#cevast.dataset.managers.manager.DatasetManager">DatasetManager</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Return a corresponding DatasetManager class based on <code>dataset_type</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def get_manager(cls, dataset_type: Union[DatasetType, str]) -&gt; Type[managers.DatasetManager]:
    &#34;&#34;&#34;Return a corresponding DatasetManager class based on `dataset_type`.&#34;&#34;&#34;
    if not cls.__classes:
        cls.__load_classes()

    # Validate and init dataset manager
    if not DatasetType.validate(dataset_type):
        raise DatasetInvalidError(&#34;Dataset type %s is not valid.&#34; % dataset_type)
    if str(dataset_type) not in cls.__classes:
        raise DatasetInvalidError(&#34;Dataset type %s has no manager.&#34; % dataset_type)

    return cls.__classes[str(dataset_type)]</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="cevast.dataset.DatasetManagerTask"><code class="flex name class">
<span>class <span class="ident">DatasetManagerTask</span></span>
<span>(</span><span>value, names=None, *, module=None, qualname=None, type=None, start=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Enumeration of DatasetManager Tasks</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DatasetManagerTask(IntEnum):
    &#34;&#34;&#34;Enumeration of DatasetManager Tasks&#34;&#34;&#34;

    COLLECT = 1
    ANALYSE = 2
    PARSE = 3
    VALIDATE = 4

    @classmethod
    def validate(cls, state: Union[&#39;DatasetManagerTask&#39;, str]) -&gt; bool:
        &#34;&#34;&#34;Validate DatasetManagerTask.&#34;&#34;&#34;
        if isinstance(state, cls):
            return state in cls
        if isinstance(state, str):
            return state in cls.__members__
        return False

    def __str__(self):
        return str(self.name)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.IntEnum</li>
<li>builtins.int</li>
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="cevast.dataset.DatasetManagerTask.ANALYSE"><code class="name">var <span class="ident">ANALYSE</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="cevast.dataset.DatasetManagerTask.COLLECT"><code class="name">var <span class="ident">COLLECT</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="cevast.dataset.DatasetManagerTask.PARSE"><code class="name">var <span class="ident">PARSE</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="cevast.dataset.DatasetManagerTask.VALIDATE"><code class="name">var <span class="ident">VALIDATE</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="cevast.dataset.DatasetParsingError"><code class="flex name class">
<span>class <span class="ident">DatasetParsingError</span></span>
<span>(</span><span>...)</span>
</code></dt>
<dd>
<div class="desc"><p>Raised when dataset parsing fails.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DatasetParsingError(ValueError):
    &#34;&#34;&#34;Raised when dataset parsing fails.&#34;&#34;&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.ValueError</li>
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="cevast.dataset.DatasetRepository"><code class="flex name class">
<span>class <span class="ident">DatasetRepository</span></span>
<span>(</span><span>repository: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper around the whole dataset repository providing overview and abstraction of the storage system.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DatasetRepository:
    &#34;&#34;&#34;
    Wrapper around the whole dataset repository providing overview and abstraction of the storage system.
    &#34;&#34;&#34;

    def __init__(self, repository: str):
        if repository and os.path.exists(repository):
            self.repository = os.path.abspath(repository)
        else:
            raise FileNotFoundError(&#34;Dataset Repository %s not found.&#34; % repository)

    def dumps(self, dataset_type: Union[DatasetType, str] = None,
              state: Union[DatasetState, str] = None, dataset_id: str = &#39;&#39;) -&gt; str:
        &#34;&#34;&#34;
        Return string representation of the specified dataset repository.
        The parameters represent the output filter options.
        &#34;&#34;&#34;
        repo = self.get(dataset_type, state, dataset_id)
        repo_str = &#39;&#39;
        for d_type, d_states in repo.items():
            for d_state, d_datasets in d_states.items():
                if d_datasets:
                    repo_str += &#34;{}: {}: [{}]\n&#34;.format(d_type, d_state, &#39;, &#39;.join(d_datasets))
        return repo_str

    def dump(self, dataset_type: Union[DatasetType, str] = None,
             state: Union[DatasetState, str] = None, dataset_id: str = &#39;&#39;) -&gt; None:
        &#34;&#34;&#34;
        Print string representation of the specified dataset repository to the STDOUT.
        The parameters represent the output filter options.
        &#34;&#34;&#34;
        print(self.dumps(dataset_type, state, dataset_id))

    def get(self, dataset_type: Union[DatasetType, str] = None,
            state: Union[DatasetState, str] = None, dataset_id: str = &#39;&#39;) -&gt; dict:
        &#34;&#34;&#34;
        Return dictionary representation of the specified dataset repository.
        The parameters represent the output filter options.
        &#34;&#34;&#34;

        def get_type() -&gt; dict:
            ret_type = {}
            states = [state] if state else DatasetState
            # Iterate through filtered states and get its datasets
            for d_state in states:
                ret_state = dataset_path.get(d_state)
                if ret_state:
                    ret_type[str(d_state)] = ret_state
            return ret_type

        # Validate dataset type
        if dataset_type and not DatasetType.validate(dataset_type):
            raise DatasetInvalidError(&#34;Dataset type %s is not valid.&#34; % dataset_type)
        # Validate dataset state
        if state and not DatasetState.validate(state):
            raise DatasetInvalidError(&#34;Dataset state %s is not valid.&#34; % state)

        ret_repo = {}
        types = [dataset_type] if dataset_type else DatasetType
        # Iterate through filtered types and get its states
        for d_type in types:
            dataset_path = Dataset(self.repository, d_type, dataset_id, None)
            ret_type = get_type()
            if ret_type:
                ret_repo[str(d_type)] = ret_type

        return ret_repo

    def __str__(self):
        return self.dumps()</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="cevast.dataset.DatasetRepository.dump"><code class="name flex">
<span>def <span class="ident">dump</span></span>(<span>self, dataset_type: Union[cevast.dataset.dataset.DatasetType, str] = None, state: Union[cevast.dataset.dataset.DatasetState, str] = None, dataset_id: str = '') -> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Print string representation of the specified dataset repository to the STDOUT.
The parameters represent the output filter options.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dump(self, dataset_type: Union[DatasetType, str] = None,
         state: Union[DatasetState, str] = None, dataset_id: str = &#39;&#39;) -&gt; None:
    &#34;&#34;&#34;
    Print string representation of the specified dataset repository to the STDOUT.
    The parameters represent the output filter options.
    &#34;&#34;&#34;
    print(self.dumps(dataset_type, state, dataset_id))</code></pre>
</details>
</dd>
<dt id="cevast.dataset.DatasetRepository.dumps"><code class="name flex">
<span>def <span class="ident">dumps</span></span>(<span>self, dataset_type: Union[cevast.dataset.dataset.DatasetType, str] = None, state: Union[cevast.dataset.dataset.DatasetState, str] = None, dataset_id: str = '') -> str</span>
</code></dt>
<dd>
<div class="desc"><p>Return string representation of the specified dataset repository.
The parameters represent the output filter options.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dumps(self, dataset_type: Union[DatasetType, str] = None,
          state: Union[DatasetState, str] = None, dataset_id: str = &#39;&#39;) -&gt; str:
    &#34;&#34;&#34;
    Return string representation of the specified dataset repository.
    The parameters represent the output filter options.
    &#34;&#34;&#34;
    repo = self.get(dataset_type, state, dataset_id)
    repo_str = &#39;&#39;
    for d_type, d_states in repo.items():
        for d_state, d_datasets in d_states.items():
            if d_datasets:
                repo_str += &#34;{}: {}: [{}]\n&#34;.format(d_type, d_state, &#39;, &#39;.join(d_datasets))
    return repo_str</code></pre>
</details>
</dd>
<dt id="cevast.dataset.DatasetRepository.get"><code class="name flex">
<span>def <span class="ident">get</span></span>(<span>self, dataset_type: Union[cevast.dataset.dataset.DatasetType, str] = None, state: Union[cevast.dataset.dataset.DatasetState, str] = None, dataset_id: str = '') -> dict</span>
</code></dt>
<dd>
<div class="desc"><p>Return dictionary representation of the specified dataset repository.
The parameters represent the output filter options.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get(self, dataset_type: Union[DatasetType, str] = None,
        state: Union[DatasetState, str] = None, dataset_id: str = &#39;&#39;) -&gt; dict:
    &#34;&#34;&#34;
    Return dictionary representation of the specified dataset repository.
    The parameters represent the output filter options.
    &#34;&#34;&#34;

    def get_type() -&gt; dict:
        ret_type = {}
        states = [state] if state else DatasetState
        # Iterate through filtered states and get its datasets
        for d_state in states:
            ret_state = dataset_path.get(d_state)
            if ret_state:
                ret_type[str(d_state)] = ret_state
        return ret_type

    # Validate dataset type
    if dataset_type and not DatasetType.validate(dataset_type):
        raise DatasetInvalidError(&#34;Dataset type %s is not valid.&#34; % dataset_type)
    # Validate dataset state
    if state and not DatasetState.validate(state):
        raise DatasetInvalidError(&#34;Dataset state %s is not valid.&#34; % state)

    ret_repo = {}
    types = [dataset_type] if dataset_type else DatasetType
    # Iterate through filtered types and get its states
    for d_type in types:
        dataset_path = Dataset(self.repository, d_type, dataset_id, None)
        ret_type = get_type()
        if ret_type:
            ret_repo[str(d_type)] = ret_type

    return ret_repo</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="cevast.dataset.DatasetState"><code class="flex name class">
<span>class <span class="ident">DatasetState</span></span>
<span>(</span><span>value, names=None, *, module=None, qualname=None, type=None, start=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Enumaration class of all supported Dataset states.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DatasetState(IntEnum):
    &#34;&#34;&#34;Enumaration class of all supported Dataset states.&#34;&#34;&#34;

    COLLECTED = 1  # Dataset was collected and is available in a raw format
    ANALYZED = 2  # Dataset was analyzed
    PARSED = 3  # Dataset was parsed to internal format, certificates were stored to CertDB
    VALIDATED = 4  # Dataset was already run through validation, result might be available

    @classmethod
    def validate(cls, state: Union[&#39;DatasetState&#39;, str]) -&gt; bool:
        &#34;&#34;&#34;Validate DatasetState.&#34;&#34;&#34;
        if isinstance(state, cls):
            return state in cls
        if isinstance(state, str):
            return state in cls.__members__
        return False

    def __str__(self):
        return str(self.name)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.IntEnum</li>
<li>builtins.int</li>
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="cevast.dataset.DatasetState.ANALYZED"><code class="name">var <span class="ident">ANALYZED</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="cevast.dataset.DatasetState.COLLECTED"><code class="name">var <span class="ident">COLLECTED</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="cevast.dataset.DatasetState.PARSED"><code class="name">var <span class="ident">PARSED</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="cevast.dataset.DatasetState.VALIDATED"><code class="name">var <span class="ident">VALIDATED</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="cevast.dataset.DatasetType"><code class="flex name class">
<span>class <span class="ident">DatasetType</span></span>
<span>(</span><span>value, names=None, *, module=None, qualname=None, type=None, start=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Enumaration class of all supported Dataset types.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DatasetType(IntEnum):
    &#34;&#34;&#34;Enumaration class of all supported Dataset types.&#34;&#34;&#34;

    RAPID = 1
    CENSYS = 2

    @classmethod
    def validate(cls, dataset_type: Union[&#39;DatasetType&#39;, str]) -&gt; bool:
        &#34;&#34;&#34;Validate DatasetType.&#34;&#34;&#34;
        if isinstance(dataset_type, cls):
            return dataset_type in cls
        if isinstance(dataset_type, str):
            return dataset_type in cls.__members__
        return False

    def __str__(self):
        return str(self.name)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.IntEnum</li>
<li>builtins.int</li>
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="cevast.dataset.DatasetType.CENSYS"><code class="name">var <span class="ident">CENSYS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="cevast.dataset.DatasetType.RAPID"><code class="name">var <span class="ident">RAPID</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="cevast" href="../index.html">cevast</a></code></li>
</ul>
</li>
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="cevast.dataset.analyses" href="analyses/index.html">cevast.dataset.analyses</a></code></li>
<li><code><a title="cevast.dataset.collectors" href="collectors/index.html">cevast.dataset.collectors</a></code></li>
<li><code><a title="cevast.dataset.dataset" href="dataset.html">cevast.dataset.dataset</a></code></li>
<li><code><a title="cevast.dataset.manager_factory" href="manager_factory.html">cevast.dataset.manager_factory</a></code></li>
<li><code><a title="cevast.dataset.managers" href="managers/index.html">cevast.dataset.managers</a></code></li>
<li><code><a title="cevast.dataset.parsers" href="parsers/index.html">cevast.dataset.parsers</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="cevast.dataset.Dataset" href="#cevast.dataset.Dataset">Dataset</a></code></h4>
<ul class="two-column">
<li><code><a title="cevast.dataset.Dataset.dataset_type" href="#cevast.dataset.Dataset.dataset_type">dataset_type</a></code></li>
<li><code><a title="cevast.dataset.Dataset.date" href="#cevast.dataset.Dataset.date">date</a></code></li>
<li><code><a title="cevast.dataset.Dataset.delete" href="#cevast.dataset.Dataset.delete">delete</a></code></li>
<li><code><a title="cevast.dataset.Dataset.exists" href="#cevast.dataset.Dataset.exists">exists</a></code></li>
<li><code><a title="cevast.dataset.Dataset.exists_any" href="#cevast.dataset.Dataset.exists_any">exists_any</a></code></li>
<li><code><a title="cevast.dataset.Dataset.extension" href="#cevast.dataset.Dataset.extension">extension</a></code></li>
<li><code><a title="cevast.dataset.Dataset.format_filename" href="#cevast.dataset.Dataset.format_filename">format_filename</a></code></li>
<li><code><a title="cevast.dataset.Dataset.from_full_path" href="#cevast.dataset.Dataset.from_full_path">from_full_path</a></code></li>
<li><code><a title="cevast.dataset.Dataset.full_path" href="#cevast.dataset.Dataset.full_path">full_path</a></code></li>
<li><code><a title="cevast.dataset.Dataset.get" href="#cevast.dataset.Dataset.get">get</a></code></li>
<li><code><a title="cevast.dataset.Dataset.move" href="#cevast.dataset.Dataset.move">move</a></code></li>
<li><code><a title="cevast.dataset.Dataset.path" href="#cevast.dataset.Dataset.path">path</a></code></li>
<li><code><a title="cevast.dataset.Dataset.port" href="#cevast.dataset.Dataset.port">port</a></code></li>
<li><code><a title="cevast.dataset.Dataset.purge" href="#cevast.dataset.Dataset.purge">purge</a></code></li>
<li><code><a title="cevast.dataset.Dataset.static_filename" href="#cevast.dataset.Dataset.static_filename">static_filename</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="cevast.dataset.DatasetCollectionError" href="#cevast.dataset.DatasetCollectionError">DatasetCollectionError</a></code></h4>
</li>
<li>
<h4><code><a title="cevast.dataset.DatasetInvalidError" href="#cevast.dataset.DatasetInvalidError">DatasetInvalidError</a></code></h4>
</li>
<li>
<h4><code><a title="cevast.dataset.DatasetManager" href="#cevast.dataset.DatasetManager">DatasetManager</a></code></h4>
<ul class="two-column">
<li><code><a title="cevast.dataset.DatasetManager.analyse" href="#cevast.dataset.DatasetManager.analyse">analyse</a></code></li>
<li><code><a title="cevast.dataset.DatasetManager.collect" href="#cevast.dataset.DatasetManager.collect">collect</a></code></li>
<li><code><a title="cevast.dataset.DatasetManager.dataset_type" href="#cevast.dataset.DatasetManager.dataset_type">dataset_type</a></code></li>
<li><code><a title="cevast.dataset.DatasetManager.parse" href="#cevast.dataset.DatasetManager.parse">parse</a></code></li>
<li><code><a title="cevast.dataset.DatasetManager.run" href="#cevast.dataset.DatasetManager.run">run</a></code></li>
<li><code><a title="cevast.dataset.DatasetManager.validate" href="#cevast.dataset.DatasetManager.validate">validate</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="cevast.dataset.DatasetManagerFactory" href="#cevast.dataset.DatasetManagerFactory">DatasetManagerFactory</a></code></h4>
<ul class="">
<li><code><a title="cevast.dataset.DatasetManagerFactory.get_manager" href="#cevast.dataset.DatasetManagerFactory.get_manager">get_manager</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="cevast.dataset.DatasetManagerTask" href="#cevast.dataset.DatasetManagerTask">DatasetManagerTask</a></code></h4>
<ul class="">
<li><code><a title="cevast.dataset.DatasetManagerTask.ANALYSE" href="#cevast.dataset.DatasetManagerTask.ANALYSE">ANALYSE</a></code></li>
<li><code><a title="cevast.dataset.DatasetManagerTask.COLLECT" href="#cevast.dataset.DatasetManagerTask.COLLECT">COLLECT</a></code></li>
<li><code><a title="cevast.dataset.DatasetManagerTask.PARSE" href="#cevast.dataset.DatasetManagerTask.PARSE">PARSE</a></code></li>
<li><code><a title="cevast.dataset.DatasetManagerTask.VALIDATE" href="#cevast.dataset.DatasetManagerTask.VALIDATE">VALIDATE</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="cevast.dataset.DatasetParsingError" href="#cevast.dataset.DatasetParsingError">DatasetParsingError</a></code></h4>
</li>
<li>
<h4><code><a title="cevast.dataset.DatasetRepository" href="#cevast.dataset.DatasetRepository">DatasetRepository</a></code></h4>
<ul class="">
<li><code><a title="cevast.dataset.DatasetRepository.dump" href="#cevast.dataset.DatasetRepository.dump">dump</a></code></li>
<li><code><a title="cevast.dataset.DatasetRepository.dumps" href="#cevast.dataset.DatasetRepository.dumps">dumps</a></code></li>
<li><code><a title="cevast.dataset.DatasetRepository.get" href="#cevast.dataset.DatasetRepository.get">get</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="cevast.dataset.DatasetState" href="#cevast.dataset.DatasetState">DatasetState</a></code></h4>
<ul class="">
<li><code><a title="cevast.dataset.DatasetState.ANALYZED" href="#cevast.dataset.DatasetState.ANALYZED">ANALYZED</a></code></li>
<li><code><a title="cevast.dataset.DatasetState.COLLECTED" href="#cevast.dataset.DatasetState.COLLECTED">COLLECTED</a></code></li>
<li><code><a title="cevast.dataset.DatasetState.PARSED" href="#cevast.dataset.DatasetState.PARSED">PARSED</a></code></li>
<li><code><a title="cevast.dataset.DatasetState.VALIDATED" href="#cevast.dataset.DatasetState.VALIDATED">VALIDATED</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="cevast.dataset.DatasetType" href="#cevast.dataset.DatasetType">DatasetType</a></code></h4>
<ul class="">
<li><code><a title="cevast.dataset.DatasetType.CENSYS" href="#cevast.dataset.DatasetType.CENSYS">CENSYS</a></code></li>
<li><code><a title="cevast.dataset.DatasetType.RAPID" href="#cevast.dataset.DatasetType.RAPID">RAPID</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>